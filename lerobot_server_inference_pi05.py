"""
lerobot_server_inference_pi05.py
LeRobot å®˜æ–¹é£æ ¼å®æœºæ¨ç†æœåŠ¡
ç‰¹ç‚¹ï¼šä½¿ç”¨å®˜æ–¹ Processor æµæ°´çº¿ï¼Œè‡ªåŠ¨å¤„ç† Resizeã€Prompt æ„é€ å’Œå½’ä¸€åŒ–
"""
import zmq
import torch
import pickle
import numpy as np
import cv2
import json
import os
from peft import PeftModel
from huggingface_hub import hf_hub_download

# --- LeRobot æ ¸å¿ƒç»„ä»¶ ---
from lerobot.policies.pi05.modeling_pi05 import PI05Policy
from lerobot.policies.pi05.configuration_pi05 import PI05Config
from lerobot.policies.pi05.processor_pi05 import make_pi05_pre_post_processors
from lerobot.configs.types import FeatureType, NormalizationMode, PolicyFeature
from lerobot.utils.visualization_utils import init_rerun, log_rerun_data
import pprint

# ================= é…ç½®åŒºåŸŸ =================
ADAPTER_REPO_ID = "moriis/pi05_piper_third_v3"
BASE_MODEL_ID = "lerobot/pi05_base"

PORT = 5555
DEVICE = "cuda"
VISUALIZE = False

# ç¡¬ä»¶åç§° -> æ¨¡å‹è¾“å…¥åç§° çš„æ˜ å°„
CAMERA_MAPPING = {
    "pikaGripperDepthCamera":   "observation.images.pikaGripperDepthCamera",
    "pikaGripperFisheyeCamera": "observation.images.pikaGripperFisheyeCamera",
    "pikaThirdPersonCamera":    "observation.images.pikaThirdPersonCamera",
}
STATS_PATH = "../lerobot_dataset_third_v2/meta/stats.json"
# ===========================================

def load_dataset_stats(stats_path, device="cpu"):
    """åŠ è½½ç»Ÿè®¡æ–‡ä»¶å¹¶è½¬æ¢ä¸º Tensor (å·¥å‚å‡½æ•°éœ€è¦)"""
    print(f"Loading stats from: {stats_path}")
    if not os.path.exists(stats_path):
        raise FileNotFoundError(f"Stats file not found: {stats_path}")
    with open(stats_path, 'r') as f:
        stats_dict = json.load(f)
    
    def convert(item):
        if isinstance(item, dict): return {k: convert(v) for k, v in item.items()}
        if isinstance(item, list): return torch.tensor(item, dtype=torch.float32, device=device)
        return item
    return convert(stats_dict)

def get_clean_config(repo_id):
    """æ‰‹åŠ¨æ¸…æ´—é…ç½®ï¼Œä¿®å¤ LeRobot åŠ è½½æŠ¥é”™"""
    print(f"Downloading config from {repo_id}...")
    config_path = hf_hub_download(repo_id=repo_id, filename="config.json")
    with open(config_path, "r") as f:
        cfg_dict = json.load(f)

    # 1. ç§»é™¤ä¸å…¼å®¹å­—æ®µ
    for k in ["type", "transformers_version", "_commit_hash", "peft", "use_peft"]:
        if k in cfg_dict: del cfg_dict[k]

    # 2. ä¿®å¤ Enum
    if "normalization_mapping" in cfg_dict:
        norm_map = {}
        for k, v in cfg_dict["normalization_mapping"].items():
            norm_map[k] = NormalizationMode[v] if isinstance(v, str) else v
        cfg_dict["normalization_mapping"] = norm_map

    # 3. ä¿®å¤ Feature ç±»å‹
    def fix_features(feats):
        new_feats = {}
        for k, v in feats.items():
            if isinstance(v, dict):
                if "type" in v and isinstance(v["type"], str): v["type"] = FeatureType[v["type"]]
                new_feats[k] = PolicyFeature(**v)
            else:
                new_feats[k] = v
        return new_feats
    
    cfg_dict["input_features"] = fix_features(cfg_dict.get("input_features", {}))
    cfg_dict["output_features"] = fix_features(cfg_dict.get("output_features", {}))
    
    return PI05Config(**cfg_dict)

def main():
    # ---------------- åˆå§‹åŒ–æ¨¡å‹ä¸æµæ°´çº¿ ----------------
    try:
        # 1. å‡†å¤‡é…ç½®å’Œç»Ÿè®¡æ•°æ®
        user_config = get_clean_config(ADAPTER_REPO_ID)
        pprint.pprint(user_config)
        dataset_stats = load_dataset_stats(STATS_PATH, device=DEVICE)

        # 2. åŠ è½½ Policy (Base + Adapter)
        print(f"Loading Policy (Base: {BASE_MODEL_ID})...")
        policy = PI05Policy.from_pretrained(BASE_MODEL_ID, config=user_config)
        print(f"Loading Adapter ({ADAPTER_REPO_ID})...")
        policy = PeftModel.from_pretrained(policy, ADAPTER_REPO_ID)
        policy.to(DEVICE)
        policy.eval()

        # 3. æ„å»ºå®˜æ–¹ Processor æµæ°´çº¿
        # è¿™ä¼šåˆ›å»ºç±»ä¼¼ lerobot_eval.py ä¸­çš„ env_preprocessor/preprocessor
        print("Building Official Pre/Post Processors...")
        preprocessor, postprocessor = make_pi05_pre_post_processors(
            config=user_config,
            dataset_stats=dataset_stats
        )
        # æ³¨æ„ï¼šmake_pi05_pre_post_processors åˆ›å»ºçš„ pipeline é»˜è®¤åœ¨ CPU
        # æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨å°†å†…éƒ¨æ­¥éª¤çš„ device è®¾ç½®å¥½ï¼Œæˆ–è€…åœ¨è¿è¡Œæ—¶ç”± DeviceProcessorStep å¤„ç†
        # å®˜æ–¹ä»£ç ä¸­åŒ…å« DeviceProcessorStep(device=config.device)ï¼Œæ‰€ä»¥å®ƒä¼šè‡ªåŠ¨æŠŠæ•°æ®æŒªåˆ° GPU
        
        print("âœ… System Ready!")

    except Exception as e:
        print(f"âŒ Init failed: {e}")
        import traceback; traceback.print_exc()
        return

    # ---------------- ZMQ æœåŠ¡å¾ªç¯ ----------------
    if VISUALIZE:
        init_rerun(session_name="Pi05_Real_Inference", ip="127.0.0.1", port=9876)

    context = zmq.Context()
    socket = context.socket(zmq.REP)
    socket.bind(f"tcp://*:{PORT}")
    print(f"ğŸ§ Listening on {PORT}...")

    while True:
        try:
            msg = socket.recv()
            payload = pickle.loads(msg)
            
            # === 1. æ„å»ºåŸå§‹è§‚æµ‹å­—å…¸ (Raw Observation) ===
            # è¿™é‡Œåªéœ€è¦æŠŠæ•°æ®è½¬æˆ Tensor æ ¼å¼ï¼Œæ— éœ€ Resizeï¼Œæ— éœ€ Normalizeï¼Œæ— éœ€ Batch Dim
            raw_observation = {}
            payload_images = payload.get('images', {})
            task_text = payload.get("text", "Grab the carrot and put it into the box.")
            
            # --- å›¾åƒå¤„ç† ---
            # ç›®æ ‡ï¼š[C, H, W], float32, 0-1
            imgs_ok = True
            for hw_key, model_key in CAMERA_MAPPING.items():
                if hw_key in payload_images and payload_images[hw_key] is not None:
                    nparr = np.frombuffer(payload_images[hw_key], np.uint8)
                    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    if frame is not None:
                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        # è½¬ Tensor: [H, W, C] -> [C, H, W]
                        img_tensor = torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0
                        raw_observation[model_key] = img_tensor
                    else:
                        imgs_ok = False
                else:
                    imgs_ok = False
            
            if not imgs_ok:
                print("âš ï¸ Missing images, skipping...")
                socket.send(pickle.dumps(None))
                continue

            # --- çŠ¶æ€å¤„ç† ---
            # ç›®æ ‡ï¼š[D], float32
            joints = payload.get('joint_state', [])
            if len(joints) != 7:
                socket.send(pickle.dumps(None)); continue
            
            raw_observation["observation.state"] = torch.tensor(joints, dtype=torch.float32)

            # --- ä»»åŠ¡å¤„ç† ---
            # å®˜æ–¹ Processor éœ€è¦åœ¨ complementary_data ä¸­æ‰¾åˆ°ä»»åŠ¡ï¼Œæˆ–è€…æˆ‘ä»¬ç›´æ¥é€šè¿‡ hack æ–¹å¼ä¼ å…¥
            # Pi05PrepareStateTokenizerProcessorStep é»˜è®¤ä» transition å­—å…¸é‡Œæ‰¾ task
            # æˆ‘ä»¬æ„é€ ä¸€ä¸ªåŒ…å« 'task' çš„å­—å…¸ï¼Œè¿™ç¬¦åˆ LeRobot æ•°æ®é›†è¯»å–æ—¶çš„æ ¼å¼
            input_batch = raw_observation
            # æ³¨æ„ï¼šPi05 çš„ processor æ¯”è¾ƒç‰¹æ®Šï¼Œå®ƒé€šè¿‡ task_key="task" æ¥è¯»æ–‡æœ¬
            # æˆ‘ä»¬ç›´æ¥æŠŠ task æ”¾å…¥ input_batchï¼Œå› ä¸º ProcessorStep ä¼šéå†æ•´ä¸ª dict
            # ä½†æ›´æ ‡å‡†çš„åšæ³•æ˜¯éµå¾ª processor_pi05.py çš„ transition ç»“æ„
            # ç®€å•èµ·è§ï¼Œç›´æ¥èµ‹å€¼ï¼š
            input_batch["task"] = [task_text] # æ³¨æ„è¿™é‡Œç”¨åˆ—è¡¨ï¼Œå› ä¸º AddBatchDimension ä¼šå¤„ç† Tensorï¼Œä½†å­—ç¬¦ä¸²é€šå¸¸æ˜¯åˆ—è¡¨å¤„ç†

            # === 2. æ‰§è¡Œé¢„å¤„ç†æµæ°´çº¿ (Official Pipeline) ===
            # è¿™ä¸€æ­¥ä¼šè‡ªåŠ¨ï¼š
            # 1. AddBatchDimension: [C,H,W] -> [1,C,H,W]
            # 2. Normalize State: ä½¿ç”¨ stats.json
            # 3. Prepare Prompt: æ‹¼æ¥ "Task: ..., State: ..." å¹¶ Tokenize
            # 4. Move to Device: è½¬åˆ° GPU
            
            # ä¿®æ­£ï¼šAddBatchDimensionProcessorStep å¯èƒ½ä¼šå› ä¸º "task" æ˜¯ list è€ŒæŠ¥é”™æˆ–è€…å¿½ç•¥
            # å¦‚æœ preprocessor ç¬¬ä¸€æ­¥æ˜¯ AddBatchDimensionï¼Œå®ƒæœŸæœ›è¾“å…¥æ˜¯æ—  batch çš„ Tensor
            # æˆ‘ä»¬æ‰‹åŠ¨å¤„ç†ä¸€ä¸‹ task çš„ batch é—®é¢˜
            
            with torch.no_grad():
                # è°ƒç”¨ preprocessor
                # è­¦å‘Šï¼šmake_pi05_pre_post_processors è¿”å›çš„ processor æœŸæœ›å­—å…¸ç»“æ„åŒ…å« 'observation.state' ç­‰
                batch = preprocessor(input_batch)
                # print("Processed Batch Keys:", batch.keys())
                
                
                # === 3. æ‰§è¡Œç­–ç•¥ (Policy Inference) ===
                # policy.select_action ä¼šè°ƒç”¨ predict_action_chunk
                # å†…éƒ¨ä¼šè‡ªåŠ¨è°ƒç”¨ resize_with_pad_torch (äº§ç”Ÿ -3.0 é»‘è¾¹)
                action = policy.select_action(batch)
                
                # === 4. æ‰§è¡Œåå¤„ç† (Unnormalize) ===
                # åå½’ä¸€åŒ–å¹¶ç§»é™¤ Batch ç»´åº¦
                # action: [1, Action_Dim] -> [Action_Dim]
                raw_action = postprocessor(action)
                
            # === 5. è¿”å›ç»“æœ ===
            action_np = raw_action.squeeze(0).cpu().numpy()
            print(f"Action: {action_np}")
            socket.send(pickle.dumps(action_np))

            # å¯è§†åŒ– (å¯é€‰)
            if VISUALIZE:
                # è¿™é‡Œçš„ batch['observation.images...'] å·²ç»æ˜¯ resize è¿‡çš„å—ï¼Ÿ
                # ä¸ï¼ŒPreprocessor ä¸å¤„ç†å›¾åƒ resizeï¼ŒResize æ˜¯åœ¨ Policy å†…éƒ¨å‘ç”Ÿçš„ã€‚
                # æ‰€ä»¥è¿™é‡Œå¯è§†åŒ–çš„æ˜¯åŸå§‹åˆ†è¾¨ç‡å›¾åƒã€‚
                vis_obs = {k: v.cpu() for k, v in batch.items() if isinstance(v, torch.Tensor)}
                log_rerun_data(observation=vis_obs, action=torch.from_numpy(action_np), compress_images=False)

        except Exception as e:
            print(f"Loop Error: {e}")
            import traceback; traceback.print_exc()
            socket.send(pickle.dumps(None))

if __name__ == "__main__":
    main()