"""
lerobot_server_v3.py
ä¿®å¤ç‰ˆ: æ‰‹åŠ¨æ„é€ é…ç½® -> åŠ è½½ Base -> åŠ è½½ Adapter
"""
import zmq
import torch
import pickle
import numpy as np
import cv2
import json
from peft import PeftModel
from transformers import AutoTokenizer
from huggingface_hub import hf_hub_download
import json
import os

# å¼•å…¥ LeRobot çš„æ ¸å¿ƒç±»
from lerobot.policies.pi05.modeling_pi05 import PI05Policy
from lerobot.policies.pi05.configuration_pi05 import PI05Config
from lerobot.configs.types import PolicyFeature, FeatureType, NormalizationMode
from lerobot.utils.visualization_utils import init_rerun, log_rerun_data

# å¼•å…¥åå½’ä¸€åŒ–æ‰€éœ€çš„ç±»
from lerobot.processor import UnnormalizerProcessorStep, PolicyProcessorPipeline
from lerobot.processor.converters import policy_action_to_transition, transition_to_policy_action
from lerobot.utils.constants import POLICY_POSTPROCESSOR_DEFAULT_NAME

# ================= é…ç½®åŒºåŸŸ =================
ADAPTER_REPO_ID = "moriis/pi05_piper_third_v2"
BASE_MODEL_ID = "lerobot/pi05_base"
PORT = 5555
DEVICE = "cuda"
VISUALIZE = False

# [å…³é”®] è¿™é‡Œçš„ Key å¿…é¡»å’Œ config.json é‡Œçš„å®Œå…¨ä¸€è‡´
CAMERA_MAPPING = {
    "pikaGripperDepthCamera":   "observation.images.pikaGripperDepthCamera",
    "pikaGripperFisheyeCamera": "observation.images.pikaGripperFisheyeCamera",
    "pikaThirdPersonCamera":    "observation.images.pikaThirdPersonCamera",
}

MODEL_STATE_DIM = 32
MAX_TOKEN_LEN = 200
TOKENIZER_ID = "google/paligemma-3b-pt-224"

STATS_PATH = "../lerobot_dataset_third_v2/meta/stats.json"
# ===========================================

class Pi05PromptBuilder:
    def __init__(self, joint_min, joint_max):
        self.joint_min = np.array(joint_min)
        self.joint_max = np.array(joint_max)

    def normalize_state(self, state):
        # è½¬æ¢è¾“å…¥ä¸º numpy æ•°ç»„
        state = np.array(state)
        
        # è®¡ç®—åˆ†æ¯ï¼Œé˜²æ­¢é™¤ä»¥é›¶
        denominator = self.joint_max - self.joint_min
        denominator[denominator == 0] = 1.0
        
        # Min-Max å½’ä¸€åŒ–: æ˜ å°„åˆ° [-1, 1]
        norm_state = 2 * (state - self.joint_min) / denominator - 1.0
        
        # æˆªæ–­è¶…å‡ºèŒƒå›´çš„å€¼ (è¿™å¯¹æ¨ç†å¾ˆé‡è¦ï¼Œé˜²æ­¢å¼‚å¸¸å€¼å¯¼è‡´ Token æº¢å‡º)
        return np.clip(norm_state, -1.0, 1.0)

    def discretize_state(self, norm_state):
        # çº¿æ€§åˆ†æ¡¶ [-1, 1] -> 256ä»½
        bins = np.linspace(-1, 1, 256 + 1)[:-1]
        tokens = np.digitize(norm_state, bins) - 1
        return np.clip(tokens, 0, 255)

    def build_prompt(self, task_text, joint_state):
        # 1. æ–‡æœ¬æ¸…æ´—
        clean_text = task_text.strip().replace("_", " ").replace("\n", " ")
        
        # 2. çŠ¶æ€å¤„ç† (æˆªå–å‰7ç»´)
        current_joints = joint_state[:7] 
        norm_state = self.normalize_state(current_joints)
        tokens = self.discretize_state(norm_state)
        state_str = " ".join(map(str, tokens))
        
        # 3. æ‹¼æ¥ (æ ¼å¼ä¸¥æ ¼å¯¹é½è®­ç»ƒä»£ç )
        full_prompt = f"Task: {clean_text}, State: {state_str};\nAction: "
        return full_prompt

def load_dataset_stats(stats_path, device="cpu"):
    """
    åŠ è½½ stats.json å¹¶å°†æ‰€æœ‰ list æ•°æ®è½¬æ¢ä¸º torch.Tensor
    """
    print(f"æ­£åœ¨åŠ è½½ç»Ÿè®¡æ–‡ä»¶: {stats_path}")
    if not os.path.exists(stats_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç»Ÿè®¡æ–‡ä»¶: {stats_path}")

    with open(stats_path, 'r') as f:
        stats_dict = json.load(f)

    # é€’å½’å°†æ‰€æœ‰ list è½¬ä¸º Tensor
    def convert_to_tensor(item):
        if isinstance(item, dict):
            return {k: convert_to_tensor(v) for k, v in item.items()}
        elif isinstance(item, list):
            return torch.tensor(item, dtype=torch.float32, device=device)
        return item

    dataset_stats = convert_to_tensor(stats_dict)
    
    # è·å– state çš„ min/max ç”¨äº PromptBuilder (ä¿ç•™åŸæœ‰åŠŸèƒ½)
    state_min = dataset_stats["observation.state"]["min"].cpu().numpy().tolist()
    state_max = dataset_stats["observation.state"]["max"].cpu().numpy().tolist()
    
    print("âœ… æˆåŠŸåŠ è½½ Dataset Stats (å·²è½¬æ¢ä¸º Tensor)")
    return dataset_stats, state_min, state_max

def get_task_prompt(task_text):
    # Pi0 é€šå¸¸åªéœ€è¦çº¯æ–‡æœ¬ä»»åŠ¡æè¿°ï¼ŒçŠ¶æ€ä¼šé€šè¿‡ observation.state è‡ªåŠ¨æ³¨å…¥
    # æ³¨æ„ï¼šæ ¹æ®è®­ç»ƒæ—¶çš„æ ¼å¼ï¼Œæœ‰æ—¶éœ€è¦ç‰¹å®šçš„å‰ç¼€ï¼Œæ¯”å¦‚ "Task: "
    # å¦‚æœä½ çš„æ•°æ®é›†æ˜¯æ ‡å‡†æ ¼å¼ï¼Œé€šå¸¸åªéœ€è¦æ¸…æ´—ä¸€ä¸‹æ–‡æœ¬
    return f"Task: {task_text.strip()}"

def get_clean_config(repo_id):
    """
    æ‰‹åŠ¨ä¸‹è½½å¹¶æ„å»º PI05Config å¯¹è±¡ï¼Œç»•è¿‡æ‰€æœ‰è‡ªåŠ¨åŠ è½½çš„å‘
    """
    print(f"Downloading config from {repo_id}...")
    config_path = hf_hub_download(repo_id=repo_id, filename="config.json")
    
    with open(config_path, "r") as f:
        cfg_dict = json.load(f)

    # 1. æ¸…ç†ä¸æ”¯æŒçš„å­—æ®µ
    keys_to_remove = ["type", "transformers_version", "_commit_hash", "peft", "use_peft"]
    for k in keys_to_remove:
        if k in cfg_dict:
            del cfg_dict[k]

    # 2. è½¬æ¢ Enum ç±»å‹ (NormalizationMode)
    if "normalization_mapping" in cfg_dict:
        norm_map = {}
        for k, v in cfg_dict["normalization_mapping"].items():
            # å°†å­—ç¬¦ä¸² "IDENTITY" è½¬ä¸º NormalizationMode.IDENTITY
            norm_map[k] = NormalizationMode[v] if isinstance(v, str) else v
        cfg_dict["normalization_mapping"] = norm_map

    # 3. è½¬æ¢ PolicyFeature å¯¹è±¡
    def dict_to_feature(features_dict):
        new_features = {}
        for name, data in features_dict.items():
            if isinstance(data, dict):
                # å°† "VISUAL" å­—ç¬¦ä¸²è½¬ä¸º FeatureType.VISUAL
                if "type" in data and isinstance(data["type"], str):
                    data["type"] = FeatureType[data["type"]]
                new_features[name] = PolicyFeature(**data)
            else:
                new_features[name] = data
        return new_features

    if "input_features" in cfg_dict:
        cfg_dict["input_features"] = dict_to_feature(cfg_dict["input_features"])
    
    if "output_features" in cfg_dict:
        cfg_dict["output_features"] = dict_to_feature(cfg_dict["output_features"])

    # 4. å®ä¾‹åŒ–
    return PI05Config(**cfg_dict)

def resize_with_pad(image, target_size=224):
    """
    æ¨¡æ‹Ÿ modeling_pi05.py ä¸­çš„ resize_with_pad_torch é€»è¾‘
    :param image: è¾“å…¥å›¾åƒ (H, W, C), BGR æˆ– RGB
    :param target_size: ç›®æ ‡å°ºå¯¸ (int)
    :return: å½’ä¸€åŒ–å¹¶å¡«å……åçš„ Tensor (C, H, W)
    """
    h, w = image.shape[:2]
    
    # 1. è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ (ä¿æŒé•¿å®½æ¯”)
    # ä»£ç é€»è¾‘æ˜¯: ratio = max(cur_width / width, cur_height / height)
    # è¿™æ„å‘³ç€å®ƒä¼šåŸºäºæœ€é•¿è¾¹è¿›è¡Œç¼©æ”¾ï¼Œç¡®ä¿å›¾åƒå®Œå…¨æ”¾å…¥æ¡†å†…
    scale = target_size / max(h, w)
    new_w = int(w * scale)
    new_h = int(h * scale)
    
    # 2. ç¼©æ”¾
    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    
    # 3. åˆ›å»ºç”»å¸ƒå¹¶å¡«å……
    # æ³¨æ„ï¼šè®­ç»ƒä»£ç ä¸­ padding value å¯¹äº float32 æ˜¯ -1.0
    # æˆ‘ä»¬è¿™é‡Œå…ˆç”Ÿæˆ [0, 255] çš„ uint8ï¼Œåé¢è½¬ float å†å½’ä¸€åŒ–
    # æˆ–è€…ç›´æ¥ç”Ÿæˆç°è‰²èƒŒæ™¯ (127) å¯¹åº”å½’ä¸€åŒ–åçš„ 0ï¼Œæˆ–è€…é»‘è‰² (0) å¯¹åº” -1?
    # modeling_pi05.py ä¸­: value = -1.0 (float32, æ­¤æ—¶å›¾åƒèŒƒå›´æ˜¯[-1, 1])
    # è¿™æ„å‘³ç€å¡«å……åŒºåŸŸæ˜¯ "æœ€é»‘" çš„é¢œè‰²ã€‚
    
    # åˆ›å»ºä¸€ä¸ªå…¨é»‘ç”»å¸ƒ (0)
    canvas = np.zeros((target_size, target_size, 3), dtype=np.uint8)
    
    # è®¡ç®—å±…ä¸­ä½ç½®
    top = (target_size - new_h) // 2
    left = (target_size - new_w) // 2
    
    # å¡«å…¥å›¾åƒ
    canvas[top:top+new_h, left:left+new_w] = resized
    
    # 4. è½¬ RGB (å¦‚æœè¾“å…¥æ˜¯ BGR)
    canvas = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)
    
    # 5. å½’ä¸€åŒ–åˆ° [-1, 1]
    # å…ˆè½¬ float [0, 1]
    img_tensor = torch.from_numpy(canvas).float() / 255.0
    # å†è½¬ [-1, 1] (å¡«å……çš„ 0 å˜æˆäº† -1ï¼Œä¸è®­ç»ƒä¸€è‡´)
    img_tensor = img_tensor * 2.0 - 1.0
    
    # 6. ç»´åº¦å˜æ¢ (H, W, C) -> (C, H, W)
    img_tensor = img_tensor.permute(2, 0, 1)
    
    return img_tensor

def main():
    print(f"Server A: Loading Tokenizer from {TOKENIZER_ID}...")
    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_ID, padding_side="right")

    try:
        # [Step 1] è·å–å¹²å‡€çš„é…ç½®å¯¹è±¡
        user_config = get_clean_config(ADAPTER_REPO_ID)
        
        # [Step 2] åŠ è½½ Base æ¨¡å‹ï¼Œä½†å¼ºåˆ¶æ³¨å…¥æˆ‘ä»¬çš„ Config
        # è¿™ä¸€æ­¥ä¼šä¸‹è½½å¹¶åŠ è½½ lerobot/pi05_base çš„æƒé‡ï¼Œä½†ä½¿ç”¨ pika... çš„é…ç½®
        print(f"Server A: Loading BASE weights from {BASE_MODEL_ID} with CUSTOM CONFIG...")
        policy = PI05Policy.from_pretrained(BASE_MODEL_ID, config=user_config)
        
        # [Step 3] åŠ è½½ Adapter
        print(f"Server A: Loading Adapter from {ADAPTER_REPO_ID}...")
        policy = PeftModel.from_pretrained(policy, ADAPTER_REPO_ID)
        
        policy.to(DEVICE)
        policy.eval()
        print("âœ… Server A: Policy loaded successfully!")
        
    except Exception as e:
        print(f"âŒ Error loading policy: {e}")
        import traceback
        traceback.print_exc()
        return

    
    # ä¸ºäº†é˜²æ­¢è·¯å¾„é”™è¯¯ï¼Œå¯ä»¥ä½¿ç”¨ç»å¯¹è·¯å¾„æ„å»º (å¯é€‰)
    # base_dir = os.path.dirname(os.path.abspath(__file__))
    # STATS_PATH = os.path.join(base_dir, "../lerobot_dataset_third_v2/meta/stats.json")

    try:
        # [Step 1] åŠ è½½ç»Ÿè®¡æ•°æ® (æ³¨æ„ï¼šä¼ å…¥ device ä»¥ä¾¿åç»­ GPU è®¡ç®—)
        dataset_stats, real_min, real_max = load_dataset_stats(STATS_PATH, device=DEVICE)
        
        # [Step 2] åˆå§‹åŒ– Prompt Builder
        prompt_builder = Pi05PromptBuilder(joint_min=real_min, joint_max=real_max)
        
        # [Step 3] åˆå§‹åŒ– Post-processor (åå½’ä¸€åŒ–)
        print("Server A: æ„å»º Action åå½’ä¸€åŒ–å¤„ç†å™¨...")
        unnormalizer = UnnormalizerProcessorStep(
            features=user_config.output_features,
            norm_map=user_config.normalization_mapping,
            stats=dataset_stats
        )
        postprocessor = PolicyProcessorPipeline(
            steps=[unnormalizer],
            name=POLICY_POSTPROCESSOR_DEFAULT_NAME,
            # åˆ é™¤ to_transition å’Œ to_output å‚æ•°
        )
        print("âœ… Post-processor Ready!")
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return


    if VISUALIZE:
        init_rerun(session_name="Server_Inference", ip="127.0.0.1", port=9876)

    context = zmq.Context()
    socket = context.socket(zmq.REP)
    socket.bind(f"tcp://*:{PORT}")
    print(f"ğŸ§ Server A: Listening on port {PORT}...")
    
    while True:
        try:
            msg = socket.recv()
            payload = pickle.loads(msg)
            
            task_text = payload.get("text", "Grab the carrot and put it into the box.")
            observation = {}
            payload_images = payload.get('images', {})
            
            # 1. å°è¯•è§£ç æ‰€æœ‰å­˜åœ¨çš„å›¾åƒ
            for hw_key, model_key in CAMERA_MAPPING.items():
                if hw_key in payload_images:
                    img_bytes = payload_images[hw_key]
                    if img_bytes is not None:
                        try:
                            nparr = np.frombuffer(img_bytes, np.uint8)
                            frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                            if frame is not None:
                                # 1. è½¬ RGB
                                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                                # 2. ä½¿ç”¨æ–°å‡½æ•°å¤„ç† (ç¼©æ”¾+å¡«å……+å½’ä¸€åŒ–åˆ°-1~1)
                                # æ³¨æ„: resize_with_pad å†…éƒ¨å·²ç»å®Œæˆäº† permute å’Œ å½’ä¸€åŒ–
                                observation[model_key] = resize_with_pad(frame_rgb, target_size=224)
                        except Exception:
                            pass

            missing_keys = []
            for req_key in CAMERA_MAPPING.values():
                if req_key not in observation:
                    missing_keys.append(req_key)
            
            if len(missing_keys) > 0:
                # å¦‚æœç¼ºå°‘ä»»ä½•ä¸€å¼ å›¾ï¼Œæ‹’ç»æ¨ç†
                print(f"ğŸ›‘ STRICT MODE: ä¸¢å¼ƒå¸§! ç¼ºå°‘å›¾åƒ: {missing_keys}")
                # å‘é€ None ç»™å®¢æˆ·ç«¯ï¼Œå®¢æˆ·ç«¯ä¼šæ‰“å° Warning å¹¶ä¿æŒå½“å‰å§¿æ€æˆ–é‡è¯•
                socket.send(pickle.dumps(None))
                continue # ç›´æ¥è¿›å…¥ä¸‹ä¸€æ¬¡å¾ªç¯ï¼Œä¸è·‘ inference

            # --- çŠ¶æ€å¤„ç† ---
            # 1. è·å–å…³èŠ‚æ•°æ®
            joints = payload.get('joint_state', [])
            if len(joints) != 7:
                print(f"âš ï¸ å…³èŠ‚æ•°æ®ç»´åº¦é”™è¯¯: æœŸæœ› 7, å®é™… {len(joints)}ã€‚è·³è¿‡æ­¤å¸§ã€‚")
                socket.send(pickle.dumps(None))
                continue  # ç›´æ¥è¿›å…¥ä¸‹ä¸€æ¬¡å¾ªç¯

            # 3. é«˜æ•ˆè½¬æ¢ Tensor
            state_tensor = torch.tensor(joints, dtype=torch.float32)

            # 4. å­˜å…¥è§‚æµ‹å­—å…¸
            observation["observation.state"] = state_tensor

            # --- æ¨ç† ---
            prompt_text = prompt_builder.build_prompt(task_text, joints)
            
            # è°ƒè¯•æ‰“å°ï¼Œç¡®è®¤ State æ˜¯å¦å˜æˆäº†æ•°å­—åºåˆ—
            print(f"Generated Prompt: {prompt_text}")
            
            tokenized = tokenizer(
                prompt_text, 
                return_tensors="pt", 
                padding="max_length", 
                max_length=MAX_TOKEN_LEN, 
                truncation=True
            )

            batch = {k: v.unsqueeze(0).to(DEVICE) for k, v in observation.items() if isinstance(v, torch.Tensor)}
            batch["observation.language.tokens"] = tokenized.input_ids.to(DEVICE)
            batch["observation.language.attention_mask"] = tokenized.attention_mask.to(DEVICE).bool()

            # --- æ¨ç† ---
            with torch.no_grad():
                # 1. è·å–æ¨¡å‹è¾“å‡º (Normalized)
                raw_action_norm = policy.select_action(batch)
                
                # 2. åå½’ä¸€åŒ–
                # ç¡®ä¿ç»´åº¦æ˜¯ [Batch, Dim]
                if raw_action_norm.ndim == 1:
                    raw_action_norm = raw_action_norm.unsqueeze(0)
                
                # ä½¿ç”¨ Post-processor
                action_dict = {"action": raw_action_norm}
                unnormalized_dict = postprocessor(action_dict)
                physical_action = unnormalized_dict["action"]
            
            # 3. è½¬ Numpy
            action_np = physical_action.squeeze(0).cpu().numpy()

            # è°ƒè¯•æ‰“å° (å¯¹æ¯”ä¸€ä¸‹å°±çŸ¥é“æ˜¯å¦ä¿®å¤äº†)
            # æ­£å¸¸ç‰©ç†å€¼: å¤¹çˆªåº”è¯¥åœ¨ 0.0 ~ 0.1 ä¹‹é—´ï¼Œå…³èŠ‚åº”è¯¥åœ¨ -3.14 ~ 3.14 ä¹‹é—´
            print(f"DEBUG -> Norm: {raw_action_norm[0, :3].cpu().numpy()} | Phys: {action_np[:3]}")

            socket.send(pickle.dumps(action_np))

            if VISUALIZE:
                # å¯è§†åŒ–ä¾ç„¶ä½¿ç”¨å®Œæ•´çš„ chunk
                vis_action = torch.from_numpy(action_np)
                if vis_action.ndim == 3: vis_action = vis_action[0]
                vis_obs = {k: v.cpu() for k, v in observation.items()}
                log_rerun_data(observation=vis_obs, action=vis_action, compress_images=False)

        except Exception as e:
            print(f"Error in loop: {e}")
            import traceback
            traceback.print_exc()
            socket.send(pickle.dumps(None))

if __name__ == "__main__":
    main()